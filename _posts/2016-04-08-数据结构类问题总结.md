---
layout: post
category: Lintcode
title: 数据结构类问题总结
tagline: by Archer
tags:
- Lintcode
- LeetCode
- 九章算法

---

##### 1.Trie

字典树

##### Add and search word

实现一个字典树，支持添加和模糊搜索。(.代表任意字)

整个Trie是用一个Root节点来表示的，root节点中不包含任何东西，为空。之后每个节点都有一个子节点数组，表示26个字母。

主要难点在于搜索时何时结束，helper function中第一个参数表示当前还剩下哪些字符没有匹配，current表示当前匹配的是哪个字符

结束的条件应该是 当时剩下的字符长度为0，并且当前遍历的字符处的计数不为0

{% highlight java %}
public class WordDictionary {
    
    TrieNode root = new TrieNode();
    
    public static class TrieNode{
        public int count = 0;
        public TrieNode[] subNodes;
        public TrieNode(){
            this.subNodes = new TrieNode[26];
        }
    }
    // Adds a word into the data structure.
    public void addWord(String word) {
        // Write your code here
        TrieNode current = root;
        for(int i = 0 ; i < word.length(); i ++){
            int charIndex = word.charAt(i) - 97;
            if(current.subNodes[charIndex] == null){
                current.subNodes[charIndex] = new TrieNode();
            }
            current =  current.subNodes[charIndex];
        }
        //Add one word
        current.count ++;
    }

    // Returns if the word is in the data structure. A word could
    // contain the dot character '.' to represent any one letter.
    public boolean search(String word) {
        // Write your code here
        return helper(word, root);
    }
    
    public boolean helper(String leftOver, TrieNode current){
   
        //Final node
        if(leftOver.length() == 0){
            if(current.count > 0)
                return true;
            else    
                return false;
        }
        
        boolean finalResult = false;
        char currentChar = leftOver.charAt(0);
        String nextLeftOver = leftOver.substring(1,leftOver.length());
        //When it's .
        if(currentChar == '.'){
            for(TrieNode t: current.subNodes){
                if(t != null){
                    finalResult = helper(nextLeftOver,t);
                    if(finalResult)
                        break;
                  }
                }
            return finalResult;
        }
           
        
        //When it's not .
        else{
            int charIndex = leftOver.charAt(0) - 97;
            TrieNode t = current.subNodes[charIndex];
            if(t != null){
                finalResult = helper(nextLeftOver, t);
            }
            return finalResult;
        }
    }
}

// Your WordDictionary object will be instantiated and called as such:
// WordDictionary wordDictionary = new WordDictionary();
// wordDictionary.addWord("word");
// wordDictionary.search("pattern");
{% endhighlight %}

##### Word Search 2

在一个n*m的矩阵中，寻找所有存在于字典当中的词，返回搜索到的结果

之前的word search是在n*m的矩阵中搜索一个单词，使用无向图上的深度优先就可以搜索到，搜索路径类似于搜索树

这个变体基本也是同样的原理，但是有几点不同

（1）之前的word search中，搜索字符串长度固定。在搜索路径中，如果遇到不匹配的字符就可以backtrack，如果最终搜索位置到达word.length就可以返回true

在这个问题中，字符串的长度不固定，而且是在字典里，因此我们需要在每一步遍历的时候都判断一下当前字符串是否是字典中某个字符串的前缀子串，如果不是的话就停止遍历，backtrack。
如果是的话，还需要判断一下当前字符串是不是就是某个字符串，如果是的话将当前字符串放入最终结果，并且继续遍历下去。如果不是的话就只继续遍历下去

{% highlight %}

currentString += 当前char
board[i][j] = "#"   //防止重复遍历
if currentString是字典中某个子串的前缀
	if currentString存在于字典当中
		把currentString放入最终结果
	else  //不存在于字典
		四个方向遍历
还原board[i][j]
currentString -= 当前char // Backtrack

{% endhighlight %}

Trie的构建也是有讲究的，上文的Trie构建其实写的不是很好，这个版本里面的Trie构建更好一些. SearchNode方法就是逐层搜索

{% highlight java %}
public class Solution {
    /**
     * @param board: A list of lists of character
     * @param words: A list of string
     * @return: A list of string
     */
    public static class Trie{
        TrieNode root;
        public Trie(){
            root = new TrieNode('#');
        }
      
        public void insert(String word){
            TrieNode current = root;
            for(int i = 0; i < word.length(); i ++){
                char c = word.charAt(i);
                if(current.children.get(c) == null){
                    TrieNode child = new TrieNode(c);
                    current.children.put(c, child);
                }
                current = current.children.get(c);
            }
            current.count ++;
        }
        
        public TrieNode searchNode(String word){
            HashMap<Character, TrieNode> children = root.children;
            for(int i = 0; i < word.length(); i ++){
                if(children.get(word.charAt(i)) == null)
                    return null;
                if(i == word.length() - 1){
                    return children.get(word.charAt(i));
                }
                children = children.get(word.charAt(i)).children;
            }
            return null;
        }
        
        
    }
    
    public static class TrieNode{
        HashMap<Character, TrieNode> children;
        char value;
        int count;
        public TrieNode(char c){
            children = new HashMap<Character, TrieNode>();
            value = c;
        }
    }
    public ArrayList<String> wordSearchII(char[][] board, ArrayList<String> words) {
        Trie trie = new Trie();
        for(String s : words){
            trie.insert(s);
        }
        HashSet<String> result = new HashSet<String>();
        
        for(int i = 0; i < board.length; i ++)
            for(int j = 0; j < board[0].length; j ++)
                helper(i,j, board, trie, new StringBuilder("") ,result);
                
        return new ArrayList<String>(result);
    }
    
    public void helper(int i, int j, char[][] board, Trie trie, StringBuilder sb, HashSet<String> result){
        if(i < 0 || j < 0 || i >= board.length || j >= board[0].length)
            return;
            
        char currentChar = board[i][j];
        sb.append(currentChar + "");
        TrieNode node = trie.searchNode(sb.toString());
        if(node != null){
            if(node.count > 0) 
                result.add(sb.toString());
            board[i][j] = '#';
            helper(i+1,j,board,trie,sb,result);
            helper(i-1,j,board,trie,sb,result);
            helper(i,j+1,board,trie,sb,result);
            helper(i,j-1,board,trie,sb,result);
            board[i][j] = currentChar;
        }
        sb.deleteCharAt(sb.length() - 1);
    }
}
{% endhighlight %}
##### 2.Find the weak connected component in the directed graph

弱联通分量就是指在有向图中把向去掉能构成的连通区域，这里面使用dfs已经解决不了问题，因为可能存在1->2<-3这样的联通情况，如果从1开始搜，搜到2就发现结束了，从3再开始搜，又发现一个3-》2的连通分量

那么就只有并查集了。 最开始可以认为图中每个点都是自成一个集合。然后一次遍历每一条边，如果这条边所连的两个点在不同的集合中，那么就用并查集把这两个集合中所有的元素合并起来。 然后最后扫描完整个边后，统计有多少个集合，那么最后就是弱联通分量的

仔细想一想，其实这个很像岛屿动态联通的问题。在Num of Island 1中，所有的点已经提前知道，而且属于无向图，因此DFS就可以解决问题。Num of Island 2中，岛屿动态产生，每一次让产生的节点DFS当然可以，
但是效率低，使用并查集可以达到union效率接近1。

{% highlight java %}
/**
 * Definition for Directed graph.
 * class DirectedGraphNode {
 *     int label;
 *     ArrayList<DirectedGraphNode> neighbors;
 *     DirectedGraphNode(int x) { label = x; neighbors = new ArrayList<DirectedGraphNode>(); }
 * };
 */
public class Solution {
    public static class UnionFind{
        public HashMap<Integer, Integer> ufMap;
        
        //Union other to one
        public void union(Integer one, Integer other){
          ufMap.put(find(other), find(one));
        }
        
        public Integer find(Integer element){
            while(ufMap.get(element) != element){
                element = ufMap.get(element);
            }
            return element;
        }
    }
    /**
     * @param nodes a array of Directed graph node
     * @return a connected set of a directed graph
     */
    public List<List<Integer>> connectedSet2(ArrayList<DirectedGraphNode> nodes) {
        HashMap<Integer, Integer> ufMap = new HashMap<Integer, Integer>();
        for(DirectedGraphNode node: nodes){
            ufMap.put(node.label, node.label);
        }
        UnionFind uf = new UnionFind();
        uf.ufMap = ufMap;
        
        for(DirectedGraphNode node: nodes){
           for(DirectedGraphNode neighbor: node.neighbors){
               if(uf.find(node.label) != uf.find(neighbor.label)){
                    uf.union(node.label, neighbor.label);
               }
           }
        }
        
        HashMap<Integer, List<Integer>> resultMap = new HashMap<Integer, List<Integer>>();
        for(Integer key: ufMap.keySet()){
            //Get the group it in
            Integer group = uf.find(key);
            //No such group exists before
            if(!resultMap.containsKey(group)){
                List<Integer> newList = new ArrayList<Integer>();
                newList.add(key);
                resultMap.put(group,newList); 
            }else{
                List<Integer> originList = resultMap.get(group);
                originList.add(key);
            }
        }
        List<List<Integer>> result = new ArrayList<List<Integer>>();
        for(List<Integer> e : resultMap.values()){
            Collections.sort(e);
            result.add(e);
        }
        return result;
        
        
    }
}

{% endhighlight %}

还有一道题是find connected component in undirected graph,这种问题其实就不需要深度优先了，有这样一个trick可以从图的表示中提炼出所有的节点
{% highlight java %}
   HashSet<Integer> hashSet = new HashSet<Integer>(); 
    for(UndirectedGraphNode now : nodes){
      hashSet.add(now.label);
      for(UndirectedGraphNode neighbour : now.neighbors) {
        hashSet.add(neighbour.label);
      }
    }
{% endhighlight %}

当然这题BFS更简单一些

##### Sliding window median
求动态变化的array的median，这里的median定义为第(N+1)/2 向下取整个数，如果有6个数则第3个为median，7个则是第4个数为median。

最简单的当然是每次sliding都排序，每次排序花费klogk时间，一共排(n-k)次序~n次

如果想实现nlogn的效率，可以用最大堆最小堆来实现，java的priorityQueue默认是将小的排在最顶端（最小堆），如果想用最大堆要用 PriorityQueue<Integer> maxHeap = new PriorityQueue<Integer>(k,Collections.reverseOrder());

由于即使是even也是向下取整，我们可以认定maxHeap的顶就是我们要找的median，小于等于median的数全部放在maxHeap，大于的都放在minHeap

第一个数由于两个heap都是空的，直接加到maxHeap里就好

剩下的从第二个数到第k个数，是只向两个heap中增加数的过程（窗口并不滑动），先求出当前的median(maxHeap.peek())，然后分两种情况讨论

(1)当前元素<=median,放入maxHeap, 如果之前maxHeap比minHeap已经多了一个元素（另一种可能是两个heap之前一样大小，不需要调整），那么此时maxHeap就比min多了两个，两个heap不平衡，可以将maxHeap的顶放到minHeap中

(2)>median,放入minHeap，如果之前两个heap一样大小（另一种可能是maxHeap比min多一个，不需要调整），那么此时minHeap就比max多了一个，不符合maxHeap的顶是中位数的要求，可以将minHeap的顶放到maxHeap中

从第k+1个数到第n个数，除了上面要做的这些，我们还需要删除一个之前的数，在求出这一步的median后，删除那个元素（priorityQueue有random remove的方法，时间效率为logN），然后根据堆的大小再来进行调整。并且别忘了每一步进行到最后时，将得到的结果放入result中。

记住要考虑k==0,1这样的奇葩情况。

但这么实现是有问题的，PriorityQueue能够给offer以及poll的时间效率是logn，但是对于random remove，时间效率就变成了linear了！因此，一共要进行n-k次删除，效率就是k(n-k)，n-k次增加，效率是logk(n-k),合起来是k(n-k)
##### Datastream median

和上一题一样，更简单一些

##### Ugly Number 2

Ugly Number的第一题解法是把这个数不停地除 2，3，5，直到没法再除了，如果结果不是1那就不是ugly。

这一题里求第n个ugly number，使用一个PriorityQueue，保证每次拿到的都是最小的ugly num，并且给这个出栈的num乘上2,3,5放到堆中（注意重复）


##### Segment Tree Build/Query/Modify
线段树能够保证在一个动态区间对于动态区间的某个性质的查询做到logN(n为整个区间（非要求的动态区间，而是整个区间）的长度)，更新区间上的性质也是logN

Build要根据情况，比如要是max的segment tree，就要采用后序遍历递归的方式build树

modify也是同样，左右中的方式更新

query我经常采用的则是取当前node区间的中点和query的区间相比较，如果当前node区间中点middle大于query区间的to，则左边，小于query区间的from则右边，否则，query（query区间from，middle) + query(middle + 1, query区间to），具体两个query怎么组合要根据情况考虑，可能取最大最小也可能和

##### Count of smaller numbers
给定一个数组，每个数都在[0,10000]之间，动态查询在数组某个值区间[m,n]之间的元素个数

排序后二分的方法可以做到排序nlon,查询logn（查起点和种点的位置，相减）

使用构造线段树的方法,构建树的效率是nlogn(每次edit logn，共n次)，查询时是logN，其实也没有什么区别

构建和插入都比较简单，插入的整个插入轨迹在树上是一条不分叉的直线

query也是常规方法，return的条件是到达叶子节点（from == to），在没到达叶子节点之前，根据当前query的范围，和当前node的范围有三种选择，向左，向右，分叉。

